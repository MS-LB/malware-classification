# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
from tensorflow import keras
from keras.utils import np_utils

import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

import sklearn
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

#  Pick the file to use
# file_name = '478-dataset-2-attributes'
file_name = '478-dataset-4-attributes'
# file_name = '478-dataset-8-attributes'

# Open the file and read in the data
file_path = 'reduced_dataset/' + file_name + '.csv'
raw_data = pd.read_csv(file_path)
print(raw_data)

print(raw_data[['L1-dcache-loads', 'L1-dcache-stores','class']].describe())

# Transforming the class labels into ints
transformed_data = raw_data
transformed_data['class'] = transformed_data['class'].map({'backdoor': 2, 'rootkit':3,'trojan':4,'virus':5,'worm':6, 'benign': 1})

# print(transformed_data)
# print(transformed_data.values[:,-1])





# neg, pos = np.bincount(transformed_data['class'])
# print("np.bincount")
# total = neg + pos
# print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
#     total, pos, 100 * pos / total))

# Use a utility from sklearn to split and shuffle our dataset.
train_df, test_df = train_test_split(transformed_data, test_size=0.2)
train_df, val_df = train_test_split(train_df, test_size=0.2)

# Form np arrays of labels and features.
train_labels = np.array(train_df.pop('class'))
bool_train_labels = train_labels != 0
val_labels = np.array(val_df.pop('class'))
test_labels = np.array(test_df.pop('class'))

train_labels = np_utils.to_categorical(train_labels)
print("train labels\n\n\n\n",train_labels)

val_labels = np_utils.to_categorical(val_labels)
print("val labels\n\n\n\n",val_labels)

test_labels = np_utils.to_categorical(test_labels)
print("test labels\n\n\n\n", test_labels)



train_features = np.array(train_df)
val_features = np.array(val_df)
test_features = np.array(test_df)





# one_hot_class_labels = np_utils.to_categorical(transformed_data.values[:,-1])
# print(one_hot_class_labels)
#
# train_data = np.array(transformed_data)
# print(train_data)



print("train features:")
print(train_features)
print("\n\n\nval features:")
print(val_features)
print("\n\n\ntest features:")
print(test_features)

scaler = StandardScaler()
train_features = scaler.fit_transform(train_features)

val_features = scaler.transform(val_features)
test_features = scaler.transform(test_features)

train_features = np.clip(train_features, -5, 5)
val_features = np.clip(val_features, -5, 5)
test_features = np.clip(test_features, -5, 5)


print('Training labels shape:', train_labels.shape)
print('Validation labels shape:', val_labels.shape)
print('Test labels shape:', test_labels.shape)

print('Training features shape:', train_features.shape)
print('Validation features shape:', val_features.shape)
print('Test features shape:', test_features.shape)

METRICS = [
      keras.metrics.TruePositives(name='tp'),
      keras.metrics.FalsePositives(name='fp'),
      keras.metrics.TrueNegatives(name='tn'),
      keras.metrics.FalseNegatives(name='fn'),
      keras.metrics.BinaryAccuracy(name='accuracy'),
      keras.metrics.Precision(name='precision'),
      keras.metrics.Recall(name='recall'),
      keras.metrics.AUC(name='auc'),
]

def make_model(metrics = METRICS, output_bias=None):
  if output_bias is not None:
    output_bias = tf.keras.initializers.Constant(output_bias)


  model = keras.Sequential([
      keras.layers.Dense(
          16, activation='relu',
          input_shape=(train_features.shape[-1],)),
      keras.layers.Dense(64),
      # keras.layers.Dense(128),
      # keras.layers.Dense(4, activation='sigmoid',
      #                    bias_initializer=output_bias)
      keras.layers.Dense(7, activation='softmax')
  ])

  #
  # model.add(Dense(8, input_dim=4, activation='relu'))
  # model.add(Dense(3, activation='softmax'))
  #

  # loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']

  model.compile(
      # optimizer=keras.optimizers.Adam(lr=1e-3),
      optimizer=keras.optimizers.Adam(lr=0.01),
      loss='categorical_crossentropy',
      metrics=metrics)

  return model



EPOCHS = 100
BATCH_SIZE = 100

# EPOCHS = 20
# BATCH_SIZE = 75

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_auc',
    verbose=1,
    patience=10,
    mode='max',
    restore_best_weights=True)

model = make_model()
history = model.fit(
    train_features,
    train_labels,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    callbacks = [early_stopping],
    validation_data=(val_features, val_labels))

colors = ["blue","orange"]

def plot_metrics(history):
  metrics =  ['loss', 'auc', 'precision', 'recall']
  for n, metric in enumerate(metrics):
    name = metric.replace("_"," ").capitalize()
    plt.subplot(2,2,n+1)
    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')
    plt.plot(history.epoch, history.history['val_'+metric],
             color=colors[1], linestyle="--", label='Val')
    plt.xlabel('Epoch')
    plt.ylabel(name)
    plt.title(name+" vs Epoch")
    if metric == 'loss':
      plt.ylim([0, plt.ylim()[1]])
    elif metric == 'auc':
      plt.ylim([0.8,1])
    else:
      plt.ylim([0,1])

    plt.legend()

plot_metrics(history)
# plt.show()

train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)
test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)

baseline_results = model.evaluate(test_features, test_labels,
                                  batch_size=BATCH_SIZE, verbose=0)

for name, value in zip(model.metrics_names, baseline_results):
  print(name, ': ', value)
print()

# def plot_roc(name, labels, predictions, **kwargs):
#   fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)
#
#   plt.plot(fp, tp, label=name, linewidth=2, **kwargs)
#   plt.xlabel('False positives [%]')
#   plt.ylabel('True positives [%]')
#   plt.xlim([-0.1,1])
#   plt.ylim([-0.1,1])
#   plt.grid(True)
#   ax = plt.gca()
#   ax.set_aspect('equal')
#
#
# plot_roc("Train Baseline", train_labels, train_predictions_baseline, color=colors[0])
# plot_roc("Test Baseline", test_labels, test_predictions_baseline, color=colors[1], linestyle='--')
# plt.legend(loc='lower right')
plt.show()

