import numpy as np
import pandas as pd

import sklearn
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

import imageio


# Used these values to edit the .csv files to convert the data to be between 0-255 for each column
# def div_by_256(n):
#     return int(n/256)
# #                            Max          Bin divisor
# #  branch-misses         	591493          2320
# #  branch-loads          	82718597        324387
# #  L1-dcache-loads       	37533491        147191
# #  L1-dcache-stores      	21723268        85190
# max_val_4 = [591493, 82718597, 37533491, 21723268]
# bin_count_4 = map(div_by_256, max_val_4)
#
# #                             Max          Bin divisor
# #  bus-cycles             1957393         7677
# #  branch-instructions   	35057193        137480
# #  branch-misses         	591493          2320
# #  instructions          	116254971       455902
# #  branch-loads          	82718597        324387
# #  L1-dcache-loads       	37533491        147191
# #  L1-dcache-stores      	21723268        85190
# #  iTLB-load-misses      	34729           137
# max_val_8 = [1957393, 35057193, 591493, 116254971, 82718597, 37533491, 21723268, 34729]
# bin_count_8 = map(div_by_256, max_val_8)



#  Pick the file to use
# Open the file and read in the data
file_name = 'GrayScale-4'
# file_name = 'GrayScale-8'
file_path = '../GrayScaleDataset/' + file_name + '.csv'

base_folder = "../grayscale-images-4"
# base_folder = "../grayscale-images-8"


raw_data = pd.read_csv(file_path)
print(raw_data)

# transformed_data = raw_data
# transformed_data['class'] = transformed_data['class'].map({'backdoor': True, 'rootkit':True,'trojan':True,'virus':True,'worm':True, 'benign': False})

# print(transformed_data)
# # transformed_data.pop('class')
# dataset_size= transformed_data.values.__len__()
# print("dataset_size ", dataset_size)
# image_arrays = []
# print("image_arrays ", image_arrays)
# print("image_arrays.len ", image_arrays.__len__())


# Use a utility from sklearn to split and shuffle our dataset.
train_df, test_df = train_test_split(raw_data, test_size=0.2)
train_df, val_df = train_test_split(train_df, test_size=0.2)


count = {"backdoor":0,"benign":0,"rootkit":0,"trojan":0,"virus":0,"worm":0}

dataset = [train_df, test_df, val_df]
dataset_name = ["train", "test", "val"]

for i in range(3):
    folder = dataset_name[i]
    for row in dataset[i].values:
        row_values = row[0:-1]

        # 16 x 16 input size
        # A attributes:   A*n x A*n  where n=number of duplicate values
        # 8 attributes:   8*2 x 8*2
        # 4 attributes:   4*4 x 4*4

        # 4 attributes
        # print("row ", row_values)
        half_row = np.append(row_values, row_values)
        full_row = np.append(half_row, half_row)
        # print("full ", full_row)

        # 8 attributes
        # print("row ", row_values)
        # full_row = np.append(row_values, row_values)
        # print("full ", full_row)

        a = np.empty((0, 16))
        for i in range(16):
            a = np.append(a, [full_row], axis=0)

        a = np.uint8(a)
        # f = open("temp",'rw')
        file_name = base_folder+"/"+folder + "/" + row[-1] + '-' + str(count[row[-1]]) + '.png'
        count[row[-1]] += 1
        imageio.imwrite(file_name, a)

        # image_arrays.append(g)




# grayscale_data = transformed_data['class']
# grayscale_data = pd.DataFrame(grayscale_data)
#




